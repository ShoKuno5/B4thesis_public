"Key","Item Type","Publication Year","Author","Title","Publication Title","ISBN","ISSN","DOI","Url","Abstract Note","Date","Date Added","Date Modified","Access Date","Pages","Num Pages","Issue","Volume","Number Of Volumes","Journal Abbreviation","Short Title","Series","Series Number","Series Text","Series Title","Publisher","Place","Language","Rights","Type","Archive","Archive Location","Library Catalog","Call Number","Extra","Notes","File Attachments","Link Attachments","Manual Tags","Automatic Tags","Editor","Series Editor","Translator","Contributor","Attorney Agent","Book Author","Cast Member","Commenter","Composer","Cosponsor","Counsel","Interviewer","Producer","Recipient","Reviewed Author","Scriptwriter","Words By","Guest","Number","Edition","Running Time","Scale","Medium","Artwork Size","Filing Date","Application Number","Assignee","Issuing Authority","Country","Meeting Name","Conference Name","Court","References","Reporter","Legal Status","Priority Numbers","Programming Language","Version","System","Code","Code Number","Section","Session","Committee","History","Legislative Body"
"PSCWMDRN","journalArticle","2022","Chen, Yeyuge; Qian, Yu; Cui, Xiaohua","Time series reconstructing using calibrated reservoir computing","Scientific Reports","","2045-2322","10.1038/s41598-022-20331-3","https://www.nature.com/articles/s41598-022-20331-3","Reservoir computing, a new method of machine learning, has recently been used to predict the state evolution of various chaotic dynamic systems. It has significant advantages in terms of training cost and adjusted parameters; however, the prediction length is limited. For classic reservoir computing, the prediction length can only reach five to six Lyapunov times. Here, we modified the method of reservoir computing by adding feedback, continuous or discrete, to “calibrate” the input of the reservoir and then reconstruct the entire dynamic systems. The reconstruction length appreciably increased and the training length obviously decreased. The reconstructing of dynamical systems is studied in detail under this method. The reconstruction can be significantly improved both in length and accuracy. Additionally, we summarized the effect of different kinds of input feedback. The more it interacts with others in dynamical equations, the better the reconstructions. Nonlinear terms can reveal more information than linear terms once the interaction terms are equal. This method has proven effective via several classical chaotic systems. It can be superior to traditional reservoir computing in reconstruction, provides new hints in computing promotion, and may be used in some real applications.","2022-09-29","2023-11-17 08:55:06","2023-11-17 08:55:45","2023-11-17 08:55:06","16318","","1","12","","Sci Rep","","","","","","","","en","2022 The Author(s)","","","","www.nature.com","","Number: 1 Publisher: Nature Publishing Group","","/Users/manqueenmannequin/Zotero/storage/4WWUDVEC/Chen et al. - 2022 - Time series reconstructing using calibrated reserv.pdf","","","Applied mathematics; Computational science; Nonlinear phenomena","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"L8YMIFT8","preprint","2022","Chen, Tse-Chun; Penny, Stephen G.; Smith, Timothy A.; Platt, Jason A.","`Next Generation' Reservoir Computing: an Empirical Data-Driven Expression of Dynamical Equations in Time-Stepping Form","","","","10.48550/arXiv.2201.05193","http://arxiv.org/abs/2201.05193","Next generation reservoir computing based on nonlinear vector autoregression (NVAR) is applied to emulate simple dynamical system models and compared to numerical integration schemes such as Euler and the $2^\text{nd}$ order Runge-Kutta. It is shown that the NVAR emulator can be interpreted as a data-driven method used to recover the numerical integration scheme that produced the data. It is also shown that the approach can be extended to produce high-order numerical schemes directly from data. The impacts of the presence of noise and temporal sparsity in the training set is further examined to gauge the potential use of this method for more realistic applications.","2022-01-13","2023-11-17 08:56:21","2023-11-17 08:56:21","2023-11-17 08:56:21","","","","","","","`Next Generation' Reservoir Computing","","","","","arXiv","","","","","","","arXiv.org","","arXiv:2201.05193 [cs, math]","","/Users/manqueenmannequin/Zotero/storage/IBYCXNXG/Chen et al. - 2022 - `Next Generation' Reservoir Computing an Empirica.pdf; /Users/manqueenmannequin/Zotero/storage/6JYCZ6ET/2201.html","","","Computer Science - Machine Learning; Mathematics - Dynamical Systems; Mathematics - Numerical Analysis","","","","","","","","","","","","","","","","","","","arXiv:2201.05193","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"542BJZ9E","journalArticle","2022","Barbosa, Wendson A. S.; Gauthier, Daniel J.","Learning spatiotemporal chaos using next-generation reservoir computing","Chaos: An Interdisciplinary Journal of Nonlinear Science","","1054-1500","10.1063/5.0098707","https://doi.org/10.1063/5.0098707","Forecasting the behavior of high-dimensional dynamical systems using machine learning requires efficient methods to learn the underlying physical model. We demonstrate spatiotemporal chaos prediction using a machine learning architecture that, when combined with a next-generation reservoir computer, displays state-of-the-art performance with a computational time 103–104 times faster for training process and training data set ∼102 times smaller than other machine learning algorithms. We also take advantage of the translational symmetry of the model to further reduce the computational cost and training data, each by a factor of ∼10.","2022-09-26","2023-11-17 08:57:45","2023-11-17 08:57:45","2023-11-17 08:57:45","093137","","9","32","","Chaos: An Interdisciplinary Journal of Nonlinear Science","","","","","","","","","","","","","Silverchair","","","","/Users/manqueenmannequin/Zotero/storage/EKFQ56H5/Barbosa and Gauthier - 2022 - Learning spatiotemporal chaos using next-generatio.pdf; /Users/manqueenmannequin/Zotero/storage/VCZRIX8S/Learning-spatiotemporal-chaos-using-next.html","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PHA2V88E","preprint","2021","Liu, Zhuo; Jin, Leisheng","Model-Free Prediction of Chaotic Systems Using High Efficient Next-generation Reservoir Computing","","","","10.48550/arXiv.2110.13614","http://arxiv.org/abs/2110.13614","To predict the future evolution of dynamical systems purely from observations of the past data is of great potential application. In this work, a new formulated paradigm of reservoir computing is proposed for achieving model-free predication for both low-dimensional and very large spatiotemporal chaotic systems. Compared with traditional reservoir computing models, it is more efficient in terms of predication length, training data set required and computational expense. By taking the Lorenz and Kuramoto-Sivashinsky equations as two classical examples of dynamical systems, numerical simulations are conducted, and the results show our model excels at predication tasks than the latest reservoir computing methods.","2021-10-19","2023-11-17 08:58:44","2023-11-17 08:58:44","2023-11-17 08:58:44","","","","","","","","","","","","arXiv","","","","","","","arXiv.org","","arXiv:2110.13614 [nlin]","","/Users/manqueenmannequin/Zotero/storage/BIUGVLNY/Liu and Jin - 2021 - Model-Free Prediction of Chaotic Systems Using Hig.pdf; /Users/manqueenmannequin/Zotero/storage/VK2DUCXY/2110.html","","","Computer Science - Neural and Evolutionary Computing; Nonlinear Sciences - Chaotic Dynamics","","","","","","","","","","","","","","","","","","","arXiv:2110.13614","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"L4MK34FC","journalArticle","2022","Steiner, Peter; Jalalvand, Azarakhsh; Stone, Simon; Birkholz, Peter","PyRCN: A Toolbox for Exploration and Application of Reservoir Computing Networks","Engineering Applications of Artificial Intelligence","","09521976","10.1016/j.engappai.2022.104964","http://arxiv.org/abs/2103.04807","Reservoir Computing Networks (RCNs) belong to a group of machine learning techniques that project the input space non-linearly into a high-dimensional feature space, where the underlying task can be solved linearly. Popular variants of RCNs are capable of solving complex tasks equivalently to widely used deep neural networks, but with a substantially simpler training paradigm based on linear regression. In this paper, we show how to uniformly describe RCNs with small and clearly defined building blocks, and we introduce the Python toolbox PyRCN (Python Reservoir Computing Networks) for optimizing, training and analyzing RCNs on arbitrarily large datasets. The tool is based on widely-used scientific packages and complies with the scikit-learn interface specification. It provides a platform for educational and exploratory analyses of RCNs, as well as a framework to apply RCNs on complex tasks including sequence processing. With a small number of building blocks, the framework allows the implementation of numerous different RCN architectures. We provide code examples on how to set up RCNs for time series prediction and for sequence classification tasks. PyRCN is around ten times faster than reference toolboxes on a benchmark task while requiring substantially less boilerplate code.","2022-08","2023-11-17 09:00:02","2023-11-17 09:00:02","2023-11-17 09:00:02","104964","","","113","","Engineering Applications of Artificial Intelligence","PyRCN","","","","","","","","","","","","arXiv.org","","arXiv:2103.04807 [cs]","","/Users/manqueenmannequin/Zotero/storage/59M96VKD/Steiner et al. - 2022 - PyRCN A Toolbox for Exploration and Application o.pdf; /Users/manqueenmannequin/Zotero/storage/NL6BSKXN/2103.html","","","Computer Science - Machine Learning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"794WQJP7","webpage","","","On explaining the surprising success of reservoir computing forecaster of chaos? The universal machine learning dynamical system with contrast to VAR and DMD | Chaos: An Interdisciplinary Journal of Nonlinear Science | AIP Publishing","","","","","https://pubs.aip.org/aip/cha/article/31/1/013108/341924/On-explaining-the-surprising-success-of-reservoir","","","2023-11-17 09:00:19","2023-11-17 09:00:19","2023-11-17 09:00:19","","","","","","","","","","","","","","","","","","","","","","","/Users/manqueenmannequin/Zotero/storage/PKRLCN7J/On-explaining-the-surprising-success-of-reservoir.html","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FSEGDBKF","journalArticle","2017","Lu, Zhixin; Pathak, Jaideep; Hunt, Brian; Girvan, Michelle; Brockett, Roger; Ott, Edward","Reservoir observers: Model-free inference of unmeasured variables in chaotic systems","Chaos: An Interdisciplinary Journal of Nonlinear Science","","1054-1500, 1089-7682","10.1063/1.4979665","https://pubs.aip.org/cha/article/27/4/041102/322542/Reservoir-observers-Model-free-inference-of","Deducing the state of a dynamical system as a function of time from a limited number of concurrent system state measurements is an important problem of great practical utility. A scheme that accomplishes this is called an “observer.” We consider the case in which a model of the system is unavailable or insufficiently accurate, but “training” time series data of the desired state variables are available for a short period of time, and a limited number of other system variables are continually measured. We propose a solution to this problem using networks of neuron-like units known as “reservoir computers.” The measurements that are continually available are input to the network, which is trained with the limited-time data to output estimates of the desired state variables. We demonstrate our method, which we call a “reservoir observer,” using the Rössler system, the Lorenz system, and the spatiotemporally chaotic Kuramoto–Sivashinsky equation. Subject to the condition of observability (i.e., whether it is in principle possible, by any means, to infer the desired unmeasured variables from the measured variables), we show that the reservoir observer can be a very effective and versatile tool for robustly reconstructing unmeasured dynamical system variables.","2017-04-01","2023-11-22 01:48:45","2023-11-22 01:48:45","2023-11-22 01:48:45","041102","","4","27","","","Reservoir observers","","","","","","","en","","","","","DOI.org (Crossref)","","","","/Users/manqueenmannequin/Zotero/storage/DN4IGGKX/Lu et al. - 2017 - Reservoir observers Model-free inference of unmea.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"83ZDN2F6","journalArticle","2019","Chen, Xiaolu; Weng, Tongfeng; Gu, Changgui; Yang, Huijie","Synchronizing hyperchaotic subsystems with a single variable: A reservoir computing approach","Physica A: Statistical Mechanics and its Applications","","0378-4371","10.1016/j.physa.2019.122273","https://www.sciencedirect.com/science/article/pii/S0378437119313160","We adopt the machine learning technique known as “reservoir computing” to investigate hyperchaos synchronism. Interestingly, we find that by virtue of this approach, synchronization of hyperchaotic subsystems is available via only one dynamical variable. Specifically, we show that by sending just a single variable, synchronization of hyperchaotic subsystem and its learned reservoir computer can be achieved. In the same fashion, one can further observe synchronism in the trained reservoir computers even when their learned hyperchaotic subsystems are mismatched. Moreover, we demonstrate that the synchronization of interest is robust in the presence of relatively high levels of extensive noise. Our work provides an alternative way of realizing synchronization in hyperchaotic systems.","2019-11-15","2023-11-22 01:51:33","2023-11-22 01:51:33","2023-11-22 01:51:33","122273","","","534","","Physica A: Statistical Mechanics and its Applications","Synchronizing hyperchaotic subsystems with a single variable","","","","","","","","","","","","ScienceDirect","","","","/Users/manqueenmannequin/Zotero/storage/GUZPFKSX/S0378437119313160.html","","","Hyperchaotic system; Reservoir computing approach; Synchronization","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PA4ACFKH","webpage","2021","Canaday, Daniel; Pomerance, Andrew; Girvan, Michelle","A Meta-learning Approach to Reservoir Computing: Time Series Prediction with Limited Data","arXiv.org","","","","https://arxiv.org/abs/2110.03722v1","Recent research has established the effectiveness of machine learning for data-driven prediction of the future evolution of unknown dynamical systems, including chaotic systems. However, these approaches require large amounts of measured time series data from the process to be predicted. When only limited data is available, forecasters are forced to impose significant model structure that may or may not accurately represent the process of interest. In this work, we present a Meta-learning Approach to Reservoir Computing (MARC), a data-driven approach to automatically extract an appropriate model structure from experimentally observed ""related"" processes that can be used to vastly reduce the amount of data required to successfully train a predictive model. We demonstrate our approach on a simple benchmark problem, where it beats the state of the art meta-learning techniques, as well as a challenging chaotic problem.","2021-10-07","2023-11-22 01:56:42","2023-11-22 02:03:28","2023-11-22 01:56:42","","","","","","","A Meta-learning Approach to Reservoir Computing","","","","","","","en","","","","","","","","","/Users/manqueenmannequin/Zotero/storage/HNED855Z/Canaday et al. - 2021 - A Meta-learning Approach to Reservoir Computing T.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RBXFQ3SA","journalArticle","2018","Nakai, Kengo; Saiki, Yoshitaka","Machine-learning inference of fluid variables from data using reservoir computing","Physical Review E","","","10.1103/PhysRevE.98.023111","https://link.aps.org/doi/10.1103/PhysRevE.98.023111","We infer both microscopic and macroscopic behaviors of a three-dimensional chaotic fluid flow using reservoir computing. In our procedure of the inference, we assume no prior knowledge of a physical process of a fluid flow except that its behavior is complex but deterministic. We present two ways of inference of the complex behavior: the first, called partial inference, requires continued knowledge of partial time-series data during the inference as well as past time-series data, while the second, called full inference, requires only past time-series data as training data. For the first case, we are able to infer long-time motion of microscopic fluid variables. For the second case, we show that the reservoir dynamics constructed from only past data of energy functions can infer the future behavior of energy functions and reproduce the energy spectrum. It is also shown that we can infer time-series data from only one measurement by using the delay coordinates. This implies that the obtained reservoir systems constructed without the knowledge of microscopic data are equivalent to the dynamical systems describing the macroscopic behavior of energy functions.","2018-08-31","2023-11-22 01:56:58","2023-11-22 01:56:58","2023-11-22 01:56:58","023111","","2","98","","Phys. Rev. E","","","","","","","","","","","","","APS","","Publisher: American Physical Society","","/Users/manqueenmannequin/Zotero/storage/SRNZ4QHQ/PhysRevE.98.html; /Users/manqueenmannequin/Zotero/storage/PY7S9I2N/Nakai and Saiki - 2018 - Machine-learning inference of fluid variables from.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BTRSTZ6A","preprint","2022","Kong, Ling-Wei; Weng, Yang; Glaz, Bryan; Haile, Mulugeta; Lai, Ying-Cheng","Digital twins of nonlinear dynamical systems","","","","10.48550/arXiv.2210.06144","http://arxiv.org/abs/2210.06144","We articulate the design imperatives for machine-learning based digital twins for nonlinear dynamical systems subject to external driving, which can be used to monitor the ``health'' of the target system and anticipate its future collapse. We demonstrate that, with single or parallel reservoir computing configurations, the digital twins are capable of challenging forecasting and monitoring tasks. Employing prototypical systems from climate, optics and ecology, we show that the digital twins can extrapolate the dynamics of the target system to certain parameter regimes never experienced before, make continual forecasting/monitoring with sparse real-time updates under non-stationary external driving, infer hidden variables and accurately predict their dynamical evolution, adapt to different forms of external driving, and extrapolate the global bifurcation behaviors to systems of some different sizes. These features make our digital twins appealing in significant applications such as monitoring the health of critical systems and forecasting their potential collapse induced by environmental changes.","2022-10-05","2023-11-22 03:04:25","2023-11-22 03:04:25","2023-11-22 03:04:25","","","","","","","","","","","","arXiv","","","","","","","arXiv.org","","arXiv:2210.06144 [nlin]","","/Users/manqueenmannequin/Zotero/storage/HNNMKAG4/Kong et al. - 2022 - Digital twins of nonlinear dynamical systems.pdf; /Users/manqueenmannequin/Zotero/storage/QEFYBVYT/2210.html","","","Computer Science - Machine Learning; Nonlinear Sciences - Adaptation and Self-Organizing Systems","","","","","","","","","","","","","","","","","","","arXiv:2210.06144","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3RGG7AWV","journalArticle","2023","Choi, Jaesung; Park, Eonyoung; Jang, Bongsoo; Kim, Yunho","Reservoir concatenation and the spectrum distribution of concatenated reservoir state matrices","AIP Advances","","2158-3226","10.1063/5.0150113","https://doi.org/10.1063/5.0150113","Reservoir computing, one of the state-of-the-art machine learning architectures, processes time-series data generated by dynamical systems. Nevertheless, we have realized that reservoir computing with the conventional single-reservoir structure suffers from capacity saturation. This leads to performance stagnation in practice. Therefore, we propose an extended reservoir computing architecture called reservoir concatenation to further delay such stagnation. Not only do we provide training error analysis and test error comparison of reservoir concatenation, but we also propose a crucial measure, which is the trace associated with a reservoir state matrix, that explains the level of responsiveness to reservoir concatenation. Two reservoir dynamics are compared in detail, one by using the echo state network and the other by using a synchronization model called an explosive Kuramoto model. The distinct eigenvalue distributions of the reservoir state matrices from the two models are well reflected in the trace values that are shown to account for the different reservoir capacity behaviors, determining the different levels of responsiveness.","2023-11-14","2023-12-01 04:17:38","2023-12-01 04:17:38","2023-12-01 04:17:38","115110","","11","13","","AIP Advances","","","","","","","","","","","","","Silverchair","","","","/Users/manqueenmannequin/Zotero/storage/U96KQCSW/Choi et al. - 2023 - Reservoir concatenation and the spectrum distribut.pdf; /Users/manqueenmannequin/Zotero/storage/STFZYDCD/Reservoir-concatenation-and-the-spectrum.html","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JBMG2GLS","journalArticle","2023","Haruna, Junichi; Toshio, Riki; Nakano, Naoto","Path integral approach to universal dynamics of reservoir computers","Physical Review E","","","10.1103/PhysRevE.107.034306","https://link.aps.org/doi/10.1103/PhysRevE.107.034306","In this work, we give a characterization of the reservoir computer (RC) by the network structure, especially the probability distribution of random coupling constants. First, based on the path integral method, we clarify the universal behavior of the random network dynamics in the thermodynamic limit, which depends only on the asymptotic behavior of the second cumulant generating functions of the network coupling constants. This result enables us to classify the random networks into several universality classes, according to the distribution function of coupling constants chosen for the networks. Interestingly, it is revealed that such a classification has a close relationship with the distribution of eigenvalues of the random coupling matrix. We also comment on the relation between our theory and some practical choices of random connectivity in the RC. Subsequently, we investigate the relationship between the RC's computational power and the network parameters for several universality classes. We perform several numerical simulations to evaluate the phase diagrams of the steady reservoir states, common-signal-induced synchronization, and the computational power in the chaotic time series inference tasks. As a result, we clarify the close relationship between these quantities, especially a remarkable computational performance near the phase transitions, which is realized even near a nonchaotic transition boundary. These results may provide us with a new perspective on the designing principle for the RC.","2023-03-14","2023-12-01 04:17:58","2023-12-01 04:17:58","2023-12-01 04:17:58","034306","","3","107","","Phys. Rev. E","","","","","","","","","","","","","APS","","Publisher: American Physical Society","","/Users/manqueenmannequin/Zotero/storage/2RSYLP3A/PhysRevE.107.html; /Users/manqueenmannequin/Zotero/storage/AFI7MAJP/Haruna et al. - 2023 - Path integral approach to universal dynamics of re.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""