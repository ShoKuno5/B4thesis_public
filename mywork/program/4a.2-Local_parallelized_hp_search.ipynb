{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6032fbb7",
   "metadata": {},
   "source": [
    "# Local parallelization of Hyper Parameter Search\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dd05ebc6",
   "metadata": {},
   "source": [
    "In this notebook, we will tackle the same problem as before but with a focus on parallelization using multiple CPU cores.\n",
    "\n",
    "Thanks to the joblib library, we will define a new `optimize_study` function and implement the necessary code for parallel execution. This parallelization can significantly speed up the hyperparameter search process.\n",
    "\n",
    "Additionally, we will provide an example to determine the optimal number of processes to use based on your local computer's capabilities."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "10ce110b",
   "metadata": {},
   "source": [
    "### Step 1 : Prepare your data "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a2038a4d",
   "metadata": {},
   "source": [
    "The first 3 steps are the same than in the 1st tutorial that explains how to conduct an hyperparameter search with optuna. You can directly jump to the 4th step if you are already familiar with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1bdcc0d1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import reservoirpy as rpy\n",
    "\n",
    "from reservoirpy.nodes import Reservoir, Ridge\n",
    "from reservoirpy.datasets import doublescroll\n",
    "from reservoirpy.observables import nrmse, rsquare\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78c3469a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "timesteps = 2000\n",
    "x0 = [0.37926545, 0.058339, -0.08167691]\n",
    "X = doublescroll(timesteps, x0=x0, method=\"RK23\")\n",
    "\n",
    "train_len = 1000\n",
    "\n",
    "X_train = X[:train_len]\n",
    "y_train = X[1 : train_len + 1]\n",
    "\n",
    "X_test = X[train_len : -1]\n",
    "y_test = X[train_len + 1:]\n",
    "\n",
    "dataset = ((X_train, y_train), (X_test, y_test))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "35615813",
   "metadata": {},
   "source": [
    "### Step 2: Define fixed parameters for the hyper parameter search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9113a69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import joblib\n",
    "import optuna\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from optuna.storages import JournalStorage, JournalFileStorage\n",
    "\n",
    "optuna.logging.set_verbosity(optuna.logging.ERROR)\n",
    "rpy.verbosity(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cecb67d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trial Fixed hyper-parameters\n",
    "nb_seeds = 3\n",
    "N = 500\n",
    "iss = 0.9\n",
    "ridge = 1e-7\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b6a8762b",
   "metadata": {},
   "source": [
    "### Step 3: Define an Objective Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "addfe513",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # Record objective values for each trial\n",
    "    losses = []\n",
    "\n",
    "    # Trial generated parameters (with log scale)\n",
    "    sr = trial.suggest_float(\"sr_1\", 1e-2, 10, log=True)\n",
    "    lr = trial.suggest_float(\"lr_1\", 1e-3, 1, log=True)\n",
    "\n",
    "    for seed in range(nb_seeds):\n",
    "        reservoir = Reservoir(N,\n",
    "                              sr=sr,\n",
    "                              lr=lr,\n",
    "                              input_scaling=iss,\n",
    "                              seed=seed)\n",
    "        \n",
    "        readout = Ridge(ridge=ridge)\n",
    "\n",
    "        model = reservoir >> readout\n",
    "\n",
    "        # Train and test your model\n",
    "        predictions = model.fit(X_train, y_train).run(X_test)\n",
    "\n",
    "        # Compute the desired metrics\n",
    "        loss = nrmse(y_test, predictions, norm_value=np.ptp(X_train))\n",
    "\n",
    "        losses.append(loss)\n",
    "\n",
    "    return np.mean(losses)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0d494f05",
   "metadata": {},
   "source": [
    "### Step 4: Create a Study Optimization function"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "19f2da3e",
   "metadata": {},
   "source": [
    "We will use the `optimize_study` function with joblib to run multiple trials in parallel.\n",
    "\n",
    "By using joblib's Parallel and delayed functionalities, we can distribute the hyperparameter optimization process across several CPU cores, simultaneously evaluating different trials. This parallelization will accelerate the search for optimal hyperparameters and improve the efficiency of the optimization process.\n",
    "\n",
    "For the storage, a SQlite one (like in the first tutorial) is not recommended to run parallel experiments as mentionned [here](https://optuna.readthedocs.io/en/stable/tutorial/10_key_features/004_distributed.html). Instead, you can use [other storages](https://optuna.readthedocs.io/en/stable/reference/storages.html) proposed by the library. Here we use a `JournalStorage` (If you use Windows and have problems with this storage, you can try to use a SQL one instead). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "64e8c089",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y4/6674dz116775fry8d67k82wm0000gn/T/ipykernel_24850/2651276384.py:9: ExperimentalWarning: JournalStorage is experimental (supported from v3.1.0). The interface can change in the future.\n",
      "  storage = JournalStorage(JournalFileStorage(log_name))\n"
     ]
    }
   ],
   "source": [
    "# Define study parameters\n",
    "nb_trials = 128\n",
    "\n",
    "sampler = optuna.samplers.RandomSampler() \n",
    "\n",
    "study_name = 'optuna_tutorial'\n",
    "log_name = f\"optuna-journal_{study_name}.log\"\n",
    "\n",
    "storage = JournalStorage(JournalFileStorage(log_name))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c72596ce",
   "metadata": {},
   "source": [
    "The argument `load_if_exists=True`enables several processes running in parallel to connect to the same storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a2bab217",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_study(n_trials):\n",
    "    study = optuna.create_study(\n",
    "        study_name='paralellization_tutorial',\n",
    "        direction='minimize',\n",
    "        storage=storage,\n",
    "        sampler=optuna.samplers.RandomSampler(),\n",
    "        load_if_exists=True\n",
    "    )\n",
    "\n",
    "    for i in range(n_trials):\n",
    "        trial = study.ask()\n",
    "        study.tell(trial, objective(trial))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "497274e7",
   "metadata": {},
   "source": [
    "### Step 5: Evaluate the optimal number of processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "933c7e34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of available CPUs : 8\n"
     ]
    }
   ],
   "source": [
    "nb_cpus = os.cpu_count()\n",
    "print(f\"Number of available CPUs : {nb_cpus}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "15ef1e90",
   "metadata": {},
   "source": [
    "The following function tests the speed of the optimization process for several values of processes (`n_processes`). This function enables you to determine the most efficient number of processes for your specific task. You can experiment with different values (inferior to `nb_cpus`), even on shorter or smaller tasks, to find the optimal configuration. Once you've identified the best number of processes, you can then apply it to the actual task you intend to perform, ensuring optimal performance.\n",
    "\n",
    "It measures the time taken to complete the optimization with each number of processes and stores the results in the times list. The code divides the total number of trials (`nb_trials`) by the number of processes to determine `n_trials_per_process`. It then uses joblib's Parallel and delayed to run optimize_study function with the specified number of trials (`n_trials_per_process`) in parallel. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3aefde76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optization with n_process = 1\n",
      "Done in 0:01:40.689247\n",
      "\n",
      "Optization with n_process = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:219: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n",
      "<frozen importlib._bootstrap>:219: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n",
      "[I 2023-11-15 21:49:47,200] Using an existing study with name 'paralellization_tutorial' instead of creating a new one.\n",
      "[I 2023-11-15 21:49:47,220] Using an existing study with name 'paralellization_tutorial' instead of creating a new one.\n",
      "Running Model-0:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Running Model-0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Running Model-0: 1000it [00:00, 14608.75it/s]         \u001b[A\n",
      "Running Model-0: 100%|██████████| 1/1 [00:00<00:00, 13.15it/s]\n",
      "Running Model-0: 1000it [00:00, 14495.06it/s]         \n",
      "Running Model-0: 100%|██████████| 1/1 [00:00<00:00, 13.69it/s]\n",
      "Running Model-0:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting node Ridge-0...\n",
      "Fitting node Ridge-0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Model-0: 999it [00:00, 15040.20it/s]          \n",
      "Running Model-0: 999it [00:00, 15061.28it/s]          \n",
      "Running Model-1:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Running Model-1:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Running Model-1: 1000it [00:00, 14856.14it/s]         \u001b[A\n",
      "Running Model-1: 100%|██████████| 1/1 [00:00<00:00, 13.45it/s]\n",
      "Running Model-1: 1000it [00:00, 14939.85it/s]         \n",
      "Running Model-1: 100%|██████████| 1/1 [00:00<00:00, 14.07it/s]\n",
      "Running Model-1:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting node Ridge-1...\n",
      "Fitting node Ridge-1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Model-1: 999it [00:00, 15025.53it/s]          \n",
      "Running Model-1: 999it [00:00, 15030.92it/s]          \n",
      "Running Model-2:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Running Model-2:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Running Model-2: 1000it [00:00, 14833.23it/s]         \u001b[A\n",
      "Running Model-2: 100%|██████████| 1/1 [00:00<00:00, 13.14it/s]\n",
      "Running Model-2: 1000it [00:00, 14885.56it/s]         \n",
      "Running Model-2: 100%|██████████| 1/1 [00:00<00:00, 13.89it/s]\n",
      "Running Model-2:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting node Ridge-2...\n",
      "Fitting node Ridge-2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Model-2: 999it [00:00, 14853.75it/s]          \n",
      "Running Model-2: 999it [00:00, 14637.78it/s]          \n",
      "Running Model-3:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Running Model-3:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Running Model-3: 1000it [00:00, 14427.89it/s]         \u001b[A\n",
      "Running Model-3: 1000it [00:00, 14677.66it/s]         \n",
      "Running Model-3: 100%|██████████| 1/1 [00:00<00:00, 12.59it/s]\n",
      "Running Model-3: 100%|██████████| 1/1 [00:00<00:00, 13.81it/s]\n",
      "Running Model-3:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting node Ridge-3...\n",
      "Fitting node Ridge-3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Model-3: 999it [00:00, 14450.95it/s]          \n",
      "Running Model-3: 999it [00:00, 15098.19it/s]          \n",
      "Running Model-4:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Running Model-4:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "mmap length is greater than file size",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/Users/manqueenmannequin/miniforge3/envs/python38gen2/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py\", line 463, in _process_worker\n    r = call_item()\n  File \"/Users/manqueenmannequin/miniforge3/envs/python38gen2/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py\", line 291, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"/Users/manqueenmannequin/miniforge3/envs/python38gen2/lib/python3.8/site-packages/joblib/parallel.py\", line 589, in __call__\n    return [func(*args, **kwargs)\n  File \"/Users/manqueenmannequin/miniforge3/envs/python38gen2/lib/python3.8/site-packages/joblib/parallel.py\", line 589, in <listcomp>\n    return [func(*args, **kwargs)\n  File \"/var/folders/y4/6674dz116775fry8d67k82wm0000gn/T/ipykernel_24850/1624097313.py\", line 12, in optimize_study\n  File \"/var/folders/y4/6674dz116775fry8d67k82wm0000gn/T/ipykernel_24850/2490947815.py\", line 21, in objective\n  File \"/Users/manqueenmannequin/miniforge3/envs/python38gen2/lib/python3.8/site-packages/reservoirpy/model.py\", line 1091, in fit\n    self.initialize_buffers()\n  File \"/Users/manqueenmannequin/miniforge3/envs/python38gen2/lib/python3.8/site-packages/reservoirpy/model.py\", line 794, in initialize_buffers\n    node.initialize_buffers()\n  File \"/Users/manqueenmannequin/miniforge3/envs/python38gen2/lib/python3.8/site-packages/reservoirpy/node.py\", line 716, in initialize_buffers\n    self._buffers_initializer(self)\n  File \"/Users/manqueenmannequin/miniforge3/envs/python38gen2/lib/python3.8/site-packages/reservoirpy/nodes/readouts/ridge.py\", line 89, in initialize_buffers\n    readout.create_buffer(\"XXT\", (input_dim, input_dim))\n  File \"/Users/manqueenmannequin/miniforge3/envs/python38gen2/lib/python3.8/site-packages/reservoirpy/node.py\", line 618, in create_buffer\n    self._buffers[name] = memmap_buffer(self, data=data, shape=shape, name=name)\n  File \"/Users/manqueenmannequin/miniforge3/envs/python38gen2/lib/python3.8/site-packages/reservoirpy/utils/parallel.py\", line 75, in memmap_buffer\n    memmap = np.memmap(temp, shape=shape, mode=mode, dtype=dtype)\n  File \"/Users/manqueenmannequin/miniforge3/envs/python38gen2/lib/python3.8/site-packages/numpy/core/memmap.py\", line 267, in __new__\n    mm = mmap.mmap(fid.fileno(), bytes, access=acc, offset=start)\nValueError: mmap length is greater than file size\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/manqueenmannequin/mygit/B4thesis_public/mywork/program/4a.2-Local_parallelized_hp_search.ipynb セル 20\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/manqueenmannequin/mygit/B4thesis_public/mywork/program/4a.2-Local_parallelized_hp_search.ipynb#X25sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m n_trials_per_process \u001b[39m=\u001b[39m nb_trials \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m n_process\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/manqueenmannequin/mygit/B4thesis_public/mywork/program/4a.2-Local_parallelized_hp_search.ipynb#X25sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m args_list \u001b[39m=\u001b[39m [n_trials_per_process \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_process)]\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/manqueenmannequin/mygit/B4thesis_public/mywork/program/4a.2-Local_parallelized_hp_search.ipynb#X25sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m joblib\u001b[39m.\u001b[39;49mParallel(n_jobs\u001b[39m=\u001b[39;49mn_process)(joblib\u001b[39m.\u001b[39;49mdelayed(optimize_study)(args) \u001b[39mfor\u001b[39;49;00m args \u001b[39min\u001b[39;49;00m args_list)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/manqueenmannequin/mygit/B4thesis_public/mywork/program/4a.2-Local_parallelized_hp_search.ipynb#X25sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m end \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/manqueenmannequin/mygit/B4thesis_public/mywork/program/4a.2-Local_parallelized_hp_search.ipynb#X25sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m times\u001b[39m.\u001b[39mappend(end \u001b[39m-\u001b[39m start)\n",
      "File \u001b[0;32m~/miniforge3/envs/python38gen2/lib/python3.8/site-packages/joblib/parallel.py:1952\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1946\u001b[0m \u001b[39m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   1947\u001b[0m \u001b[39m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   1948\u001b[0m \u001b[39m# reach the first `yield` statement. This starts the aynchronous\u001b[39;00m\n\u001b[1;32m   1949\u001b[0m \u001b[39m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   1950\u001b[0m \u001b[39mnext\u001b[39m(output)\n\u001b[0;32m-> 1952\u001b[0m \u001b[39mreturn\u001b[39;00m output \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_generator \u001b[39melse\u001b[39;00m \u001b[39mlist\u001b[39;49m(output)\n",
      "File \u001b[0;32m~/miniforge3/envs/python38gen2/lib/python3.8/site-packages/joblib/parallel.py:1595\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1592\u001b[0m     \u001b[39myield\u001b[39;00m\n\u001b[1;32m   1594\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1595\u001b[0m         \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_retrieve()\n\u001b[1;32m   1597\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1598\u001b[0m     \u001b[39m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1599\u001b[0m     \u001b[39m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1600\u001b[0m     \u001b[39m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1601\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/python38gen2/lib/python3.8/site-packages/joblib/parallel.py:1699\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1692\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_wait_retrieval():\n\u001b[1;32m   1693\u001b[0m \n\u001b[1;32m   1694\u001b[0m     \u001b[39m# If the callback thread of a worker has signaled that its task\u001b[39;00m\n\u001b[1;32m   1695\u001b[0m     \u001b[39m# triggered an exception, or if the retrieval loop has raised an\u001b[39;00m\n\u001b[1;32m   1696\u001b[0m     \u001b[39m# exception (e.g. `GeneratorExit`), exit the loop and surface the\u001b[39;00m\n\u001b[1;32m   1697\u001b[0m     \u001b[39m# worker traceback.\u001b[39;00m\n\u001b[1;32m   1698\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_aborting:\n\u001b[0;32m-> 1699\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_raise_error_fast()\n\u001b[1;32m   1700\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m   1702\u001b[0m     \u001b[39m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1703\u001b[0m     \u001b[39m# async callbacks to progress.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/python38gen2/lib/python3.8/site-packages/joblib/parallel.py:1734\u001b[0m, in \u001b[0;36mParallel._raise_error_fast\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1730\u001b[0m \u001b[39m# If this error job exists, immediatly raise the error by\u001b[39;00m\n\u001b[1;32m   1731\u001b[0m \u001b[39m# calling get_result. This job might not exists if abort has been\u001b[39;00m\n\u001b[1;32m   1732\u001b[0m \u001b[39m# called directly or if the generator is gc'ed.\u001b[39;00m\n\u001b[1;32m   1733\u001b[0m \u001b[39mif\u001b[39;00m error_job \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1734\u001b[0m     error_job\u001b[39m.\u001b[39;49mget_result(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout)\n",
      "File \u001b[0;32m~/miniforge3/envs/python38gen2/lib/python3.8/site-packages/joblib/parallel.py:736\u001b[0m, in \u001b[0;36mBatchCompletionCallBack.get_result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    730\u001b[0m backend \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparallel\u001b[39m.\u001b[39m_backend\n\u001b[1;32m    732\u001b[0m \u001b[39mif\u001b[39;00m backend\u001b[39m.\u001b[39msupports_retrieve_callback:\n\u001b[1;32m    733\u001b[0m     \u001b[39m# We assume that the result has already been retrieved by the\u001b[39;00m\n\u001b[1;32m    734\u001b[0m     \u001b[39m# callback thread, and is stored internally. It's just waiting to\u001b[39;00m\n\u001b[1;32m    735\u001b[0m     \u001b[39m# be returned.\u001b[39;00m\n\u001b[0;32m--> 736\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_return_or_raise()\n\u001b[1;32m    738\u001b[0m \u001b[39m# For other backends, the main thread needs to run the retrieval step.\u001b[39;00m\n\u001b[1;32m    739\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniforge3/envs/python38gen2/lib/python3.8/site-packages/joblib/parallel.py:754\u001b[0m, in \u001b[0;36mBatchCompletionCallBack._return_or_raise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    752\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    753\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstatus \u001b[39m==\u001b[39m TASK_ERROR:\n\u001b[0;32m--> 754\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_result\n\u001b[1;32m    755\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_result\n\u001b[1;32m    756\u001b[0m \u001b[39mfinally\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: mmap length is greater than file size"
     ]
    }
   ],
   "source": [
    "n_processes = [1, 2, 4, 8]\n",
    "times = []\n",
    "\n",
    "for n_process in n_processes:\n",
    "    print(\"\")\n",
    "    print(f\"Optization with n_process = {n_process}\")\n",
    "    start = time.time()\n",
    "\n",
    "    n_trials_per_process = nb_trials // n_process\n",
    "    args_list = [n_trials_per_process for i in range(n_process)]\n",
    "\n",
    "    joblib.Parallel(n_jobs=n_process)(joblib.delayed(optimize_study)(args) for args in args_list)\n",
    "\n",
    "    end = time.time()\n",
    "    times.append(end - start)\n",
    "    print(f\"Done in {str(datetime.timedelta(seconds=end-start))}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b18e990",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAvwAAAFzCAYAAABCVt0fAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/OQEPoAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAfz0lEQVR4nO3de4zV9Z3/8dcRdRxxQBG5zHakmIJVvLVibbFVqMqCXQri7nohVepldUUrocaWdRXsWvjJJixGUruaOLVruGyziEZdlWoAreIFZDWKCnZUvLCkVrmJg8D5/dE46SwiUhnOmS+PR/JNer7f7znnnck3zZNvPudrqVwulwMAABTSXpUeAAAAaDuCHwAACkzwAwBAgQl+AAAoMMEPAAAFJvgBAKDABD8AABSY4AcAgALbu9IDtLWtW7fmnXfeSV1dXUqlUqXHAQCAXaJcLmfdunWpr6/PXntt/z5+4YP/nXfeSUNDQ6XHAACANrFy5cp86Utf2u7xwgd/XV1dkj/9ITp16lThaQAAYNdYu3ZtGhoaWnp3eyoa/JMnT86cOXPy8ssvp7a2NgMGDMhNN92Uww8/vOWc0aNH584772z1vhNPPDGLFi36XN/xyTKeTp06CX4AAApnR8vWK/qj3QULFmTMmDFZtGhR5s2bl82bN2fw4MHZsGFDq/OGDBmSd999t2V74IEHKjQxAAC0LxW9w//ggw+2et3Y2Jhu3bpl8eLFOfnkk1v219TUpEePHrt7PAAAaPeq6rGca9asSZJ06dKl1f758+enW7du6du3by655JKsXr16u5/R3NyctWvXttoAAGBPVSqXy+VKD5H86bFCw4cPz/vvv5/HHnusZf/s2bNzwAEHpFevXmlqasp1112XzZs3Z/HixampqdnmcyZOnJgbbrhhm/1r1qyxhh8AgMJYu3ZtOnfuvMPOrZrgHzNmTO6///48/vjjn/lYoXfffTe9evXKrFmzMnLkyG2ONzc3p7m5ueX1J79eFvwAABTJ5w3+qngs55VXXpl77703Cxcu/MzYT5KePXumV69eWb58+acer6mp+dQ7/wAAsCeqaPCXy+VceeWVufvuuzN//vz07t17h+957733snLlyvTs2XM3TAgAAO1bRX+0O2bMmNx1112ZMWNG6urqsmrVqqxatSobN25Mkqxfvz5XX311nnzyybz++uuZP39+hg0blq5du+bMM8+s5OgAANAuVHQN//b+IwGNjY0ZPXp0Nm7cmBEjRuS5557LBx98kJ49e2bQoEH5l3/5lzQ0NHyu7/i8a5sAAKA9aRdr+Hf0b43a2to89NBDu2kaAAAonqp6Dj8AALBrVcVTeoruyz+9v9IjUGVe/3/fq/QISVybbKsark3XJZ/GtUm1qoZrc0fc4QcAgAIT/AAAUGCCHwAACkzwAwBAgQl+AAAoMMEPAAAFJvgBAKDABD8AABSY4AcAgAIT/AAAUGCCHwAACkzwAwBAgQl+AAAoMMEPAAAFJvgBAKDABD8AABSY4AcAgAIT/AAAUGCCHwAACkzwAwBAgQl+AAAoMMEPAAAFJvgBAKDABD8AABSY4AcAgAIT/AAAUGCCHwAACkzwAwBAgQl+AAAoMMEPAAAFJvgBAKDABD8AABSY4AcAgAIT/AAAUGCCHwAACkzwAwBAgQl+AAAoMMEPAAAFJvgBAKDABD8AABSY4AcAgAIT/AAAUGCCHwAACkzwAwBAgQl+AAAoMMEPAAAFJvgBAKDAKhr8kydPzgknnJC6urp069YtI0aMyCuvvNLqnHK5nIkTJ6a+vj61tbUZOHBgXnzxxQpNDAAA7UtFg3/BggUZM2ZMFi1alHnz5mXz5s0ZPHhwNmzY0HLOlClTMnXq1EyfPj3PPPNMevTokdNPPz3r1q2r4OQAANA+7F3JL3/wwQdbvW5sbEy3bt2yePHinHzyySmXy5k2bVquvfbajBw5Mkly5513pnv37pkxY0YuvfTSSowNAADtRlWt4V+zZk2SpEuXLkmSpqamrFq1KoMHD245p6amJqecckqeeOKJT/2M5ubmrF27ttUGAAB7qqoJ/nK5nHHjxuXb3/52jjrqqCTJqlWrkiTdu3dvdW737t1bjv1fkydPTufOnVu2hoaGth0cAACqWNUE/xVXXJHnn38+M2fO3OZYqVRq9bpcLm+z7xPjx4/PmjVrWraVK1e2ybwAANAeVHQN/yeuvPLK3HvvvVm4cGG+9KUvtezv0aNHkj/d6e/Zs2fL/tWrV29z1/8TNTU1qampaduBAQCgnajoHf5yuZwrrrgic+bMyaOPPprevXu3Ot67d+/06NEj8+bNa9m3adOmLFiwIAMGDNjd4wIAQLtT0Tv8Y8aMyYwZM3LPPfekrq6uZV1+586dU1tbm1KplLFjx2bSpEnp06dP+vTpk0mTJmX//ffPeeedV8nRAQCgXaho8N96661JkoEDB7ba39jYmNGjRydJrrnmmmzcuDGXX3553n///Zx44ol5+OGHU1dXt5unBQCA9qeiwV8ul3d4TqlUysSJEzNx4sS2HwgAAAqmap7SAwAA7HqCHwAACkzwAwBAgQl+AAAoMMEPAAAFJvgBAKDABD8AABSY4AcAgAIT/AAAUGCCHwAACkzwAwBAgQl+AAAoMMEPAAAFJvgBAKDABD8AABSY4AcAgAIT/AAAUGCCHwAACkzwAwBAgQl+AAAoMMEPAAAFJvgBAKDABD8AABSY4AcAgAIT/AAAUGCCHwAACkzwAwBAgQl+AAAoMMEPAAAFJvgBAKDABD8AABSY4AcAgAIT/AAAUGCCHwAACkzwAwBAgQl+AAAoMMEPAAAFJvgBAKDABD8AABSY4AcAgAIT/AAAUGCCHwAACkzwAwBAgQl+AAAoMMEPAAAFJvgBAKDABD8AABSY4AcAgAIT/AAAUGAVDf6FCxdm2LBhqa+vT6lUyty5c1sdHz16dEqlUqvtm9/8ZmWGBQCAdqiiwb9hw4Yce+yxmT59+nbPGTJkSN59992W7YEHHtiNEwIAQPu2dyW/fOjQoRk6dOhnnlNTU5MePXrspokAAKBYqn4N//z589OtW7f07ds3l1xySVavXl3pkQAAoN2o6B3+HRk6dGj+7u/+Lr169UpTU1Ouu+66fPe7383ixYtTU1Pzqe9pbm5Oc3Nzy+u1a9furnEBAKDqVHXwn3322S3/+6ijjkr//v3Tq1ev3H///Rk5cuSnvmfy5Mm54YYbdteIAABQ1ap+Sc+f69mzZ3r16pXly5dv95zx48dnzZo1LdvKlSt344QAAFBdqvoO///13nvvZeXKlenZs+d2z6mpqdnuch8AANjTVDT4169fnxUrVrS8bmpqytKlS9OlS5d06dIlEydOzFlnnZWePXvm9ddfzz/90z+la9euOfPMMys4NQAAtB8VDf5nn302gwYNank9bty4JMkFF1yQW2+9NS+88EJ+/etf54MPPkjPnj0zaNCgzJ49O3V1dZUaGQAA2pWKBv/AgQNTLpe3e/yhhx7ajdMAAEDxtKsf7QIAADtH8AMAQIEJfgAAKDDBDwAABSb4AQCgwP6i4N+8eXN++9vf5t///d+zbt26JMk777yT9evX79LhAACAL2anH8v5xhtvZMiQIXnzzTfT3Nyc008/PXV1dZkyZUo++uij/PKXv2yLOQEAgL/ATt/hv+qqq9K/f/+8//77qa2tbdl/5pln5pFHHtmlwwEAAF/MTt/hf/zxx/O73/0u++67b6v9vXr1yttvv73LBgMAAL64nb7Dv3Xr1mzZsmWb/W+99Vbq6up2yVAAAMCusdPBf/rpp2fatGktr0ulUtavX58JEybkjDPO2JWzAQAAX9BOL+n5t3/7twwaNChHHnlkPvroo5x33nlZvnx5unbtmpkzZ7bFjAAAwF9op4O/vr4+S5cuzcyZM7NkyZJs3bo1F110UUaNGtXqR7wAAEDl7XTwJ0ltbW0uvPDCXHjhhbt6HgAAYBf6i4L/7bffzu9+97usXr06W7dubXXsRz/60S4ZDAAA+OJ2OvgbGxtz2WWXZd99983BBx+cUqnUcqxUKgl+AACoIjsd/Ndff32uv/76jB8/PnvttdMP+QEAAHajnS72Dz/8MOecc47YBwCAdmCnq/2iiy7Kb37zm7aYBQAA2MV2eknP5MmT8zd/8zd58MEHc/TRR2efffZpdXzq1Km7bDgAAOCL2engnzRpUh566KEcfvjhSbLNj3YBAIDqsdPBP3Xq1Nxxxx0ZPXp0G4wDAADsSju9hr+mpiYnnXRSW8wCAADsYjsd/FdddVVuueWWtpgFAADYxXZ6Sc/TTz+dRx99NPfdd1/69eu3zY9258yZs8uGAwAAvpidDv4DDzwwI0eObItZAACAXWyng7+xsbEt5gAAANqA/1wuAAAU2Oe6w//1r389jzzySA466KB87Wtf+8zn7S9ZsmSXDQcAAHwxnyv4hw8fnpqamiTJiBEj2nIeAABgF/pcwT9hwoRceOGFufnmmzNhwoS2ngkAANhFPvca/jvvvDMbN25sy1kAAIBd7HMHf7lcbss5AACANrBTT+n5rB/rAgAA1WennsPft2/fHUb/H//4xy80EAAAsOvsVPDfcMMN6dy5c1vNAgAA7GI7FfznnHNOunXr1lazAAAAu9jnXsNv/T4AALQ/ntIDAAAF9rmX9GzdurUt5wAAANrATj2WEwAAaF8EPwAAFJjgBwCAAhP8AABQYIIfAAAKTPADAECBCX4AACgwwQ8AAAUm+AEAoMAEPwAAFFhFg3/hwoUZNmxY6uvrUyqVMnfu3FbHy+VyJk6cmPr6+tTW1mbgwIF58cUXKzMsAAC0QxUN/g0bNuTYY4/N9OnTP/X4lClTMnXq1EyfPj3PPPNMevTokdNPPz3r1q3bzZMCAED7tHclv3zo0KEZOnTopx4rl8uZNm1arr322owcOTJJcuedd6Z79+6ZMWNGLr300t05KgAAtEtVu4a/qakpq1atyuDBg1v21dTU5JRTTskTTzyx3fc1Nzdn7dq1rTYAANhTVW3wr1q1KknSvXv3Vvu7d+/ecuzTTJ48OZ07d27ZGhoa2nROAACoZlUb/J8olUqtXpfL5W32/bnx48dnzZo1LdvKlSvbekQAAKhaFV3D/1l69OiR5E93+nv27Nmyf/Xq1dvc9f9zNTU1qampafP5AACgPajaO/y9e/dOjx49Mm/evJZ9mzZtyoIFCzJgwIAKTgYAAO1HRe/wr1+/PitWrGh53dTUlKVLl6ZLly459NBDM3bs2EyaNCl9+vRJnz59MmnSpOy///4577zzKjg1AAC0HxUN/meffTaDBg1qeT1u3LgkyQUXXJBf/epXueaaa7Jx48Zcfvnlef/993PiiSfm4YcfTl1dXaVGBgCAdqWiwT9w4MCUy+XtHi+VSpk4cWImTpy4+4YCAIACqdo1/AAAwBcn+AEAoMAEPwAAFJjgBwCAAhP8AABQYIIfAAAKTPADAECBCX4AACgwwQ8AAAUm+AEAoMAEPwAAFJjgBwCAAhP8AABQYIIfAAAKTPADAECBCX4AACgwwQ8AAAUm+AEAoMAEPwAAFJjgBwCAAhP8AABQYIIfAAAKTPADAECBCX4AACgwwQ8AAAUm+AEAoMAEPwAAFJjgBwCAAhP8AABQYIIfAAAKTPADAECBCX4AACgwwQ8AAAUm+AEAoMAEPwAAFJjgBwCAAhP8AABQYIIfAAAKTPADAECBCX4AACgwwQ8AAAUm+AEAoMAEPwAAFJjgBwCAAhP8AABQYIIfAAAKTPADAECBCX4AACgwwQ8AAAVW1cE/ceLElEqlVluPHj0qPRYAALQbe1d6gB3p169ffvvb37a87tChQwWnAQCA9qXqg3/vvfd2Vx8AAP5CVb2kJ0mWL1+e+vr69O7dO+ecc05+//vff+b5zc3NWbt2basNAAD2VFUd/CeeeGJ+/etf56GHHsrtt9+eVatWZcCAAXnvvfe2+57Jkyenc+fOLVtDQ8NunBgAAKpLVQf/0KFDc9ZZZ+Xoo4/Oaaedlvvvvz9Jcuedd273PePHj8+aNWtatpUrV+6ucQEAoOpU/Rr+P9exY8ccffTRWb58+XbPqampSU1NzW6cCgAAqldV3+H/v5qbm7Ns2bL07Nmz0qMAAEC7UNXBf/XVV2fBggVpamrKU089lb/927/N2rVrc8EFF1R6NAAAaBeqeknPW2+9lXPPPTd/+MMfcsghh+Sb3/xmFi1alF69elV6NAAAaBeqOvhnzZpV6REAAKBdq+olPQAAwBcj+AEAoMAEPwAAFJjgBwCAAhP8AABQYIIfAAAKTPADAECBCX4AACgwwQ8AAAUm+AEAoMAEPwAAFJjgBwCAAhP8AABQYIIfAAAKTPADAECBCX4AACgwwQ8AAAUm+AEAoMAEPwAAFJjgBwCAAhP8AABQYIIfAAAKTPADAECBCX4AACgwwQ8AAAUm+AEAoMAEPwAAFJjgBwCAAhP8AABQYIIfAAAKTPADAECBCX4AACgwwQ8AAAUm+AEAoMAEPwAAFJjgBwCAAhP8AABQYIIfAAAKTPADAECBCX4AACgwwQ8AAAUm+AEAoMAEPwAAFJjgBwCAAhP8AABQYIIfAAAKTPADAECBCX4AACgwwQ8AAAUm+AEAoMDaRfD/4he/SO/evbPffvvl+OOPz2OPPVbpkQAAoF2o+uCfPXt2xo4dm2uvvTbPPfdcvvOd72To0KF58803Kz0aAABUvaoP/qlTp+aiiy7KxRdfnCOOOCLTpk1LQ0NDbr311kqPBgAAVW/vSg/wWTZt2pTFixfnpz/9aav9gwcPzhNPPPGp72lubk5zc3PL6zVr1iRJ1q5d23aD7sDW5g8r9t1Up0pej3/Otcn/VQ3XpuuST+PapFpV8tr85LvL5fJnnlfVwf+HP/whW7ZsSffu3Vvt7969e1atWvWp75k8eXJuuOGGbfY3NDS0yYzwl+g8rdITwKdzbVKtXJtUq2q4NtetW5fOnTtv93hVB/8nSqVSq9flcnmbfZ8YP358xo0b1/J669at+eMf/5iDDz54u++h7a1duzYNDQ1ZuXJlOnXqVOlxoIVrk2rl2qRauTarR7lczrp161JfX/+Z51V18Hft2jUdOnTY5m7+6tWrt7nr/4mamprU1NS02nfggQe21YjspE6dOvk/B6qSa5Nq5dqkWrk2q8Nn3dn/RFX/aHfffffN8ccfn3nz5rXaP2/evAwYMKBCUwEAQPtR1Xf4k2TcuHH5wQ9+kP79++db3/pWbrvttrz55pu57LLLKj0aAABUvaoP/rPPPjvvvfdefvazn+Xdd9/NUUcdlQceeCC9evWq9GjshJqamkyYMGGb5VZQaa5NqpVrk2rl2mx/SuUdPccHAABot6p6DT8AAPDFCH4AACgwwQ8AAAUm+AEAoMAEP21u4cKFGTZsWOrr61MqlTJ37txKjwSZPHlyTjjhhNTV1aVbt24ZMWJEXnnllUqPBa1Mnjw5pVIpY8eOrfQokM2bN+ef//mf07t379TW1uawww7Lz372s2zdurXSo7EDgp82t2HDhhx77LGZPn16pUeBFgsWLMiYMWOyaNGizJs3L5s3b87gwYOzYcOGSo8GSZJnnnkmt912W4455phKjwJJkptuuim//OUvM3369CxbtixTpkzJv/7rv+aWW26p9GjsQNU/h5/2b+jQoRk6dGilx4BWHnzwwVavGxsb061btyxevDgnn3xyhaaCP1m/fn1GjRqV22+/PTfeeGOlx4EkyZNPPpnhw4fne9/7XpLky1/+cmbOnJlnn322wpOxI+7wAyRZs2ZNkqRLly4VngSSMWPG5Hvf+15OO+20So8CLb797W/nkUceyauvvpok+Z//+Z88/vjjOeOMMyo8GTviDj+wxyuXyxk3bly+/e1v56ijjqr0OOzhZs2alSVLluSZZ56p9CjQyk9+8pOsWbMmX/3qV9OhQ4ds2bIlP//5z3PuuedWejR2QPADe7wrrrgizz//fB5//PFKj8IebuXKlbnqqqvy8MMPZ7/99qv0ONDK7Nmzc9ddd2XGjBnp169fli5dmrFjx6a+vj4XXHBBpcfjM5TK5XK50kOw5yiVSrn77rszYsSISo8CSZIrr7wyc+fOzcKFC9O7d+9Kj8Mebu7cuTnzzDPToUOHln1btmxJqVTKXnvtlebm5lbHYHdqaGjIT3/604wZM6Zl34033pi77rorL7/8cgUnY0fc4Qf2SOVyOVdeeWXuvvvuzJ8/X+xTFU499dS88MILrfb98Ic/zFe/+tX85Cc/EftU1Icffpi99mr9888OHTp4LGc7IPhpc+vXr8+KFStaXjc1NWXp0qXp0qVLDj300ApOxp5szJgxmTFjRu65557U1dVl1apVSZLOnTuntra2wtOxp6qrq9vmdyQdO3bMwQcf7PclVNywYcPy85//PIceemj69euX5557LlOnTs2FF15Y6dHYAUt6aHPz58/PoEGDttl/wQUX5Fe/+tXuHwjyp+Vln6axsTGjR4/evcPAZxg4cGCOO+64TJs2rdKjsIdbt25drrvuutx9991ZvXp16uvrc+655+b666/PvvvuW+nx+AyCHwAACsxz+AEAoMAEPwAAFJjgBwCAAhP8AABQYIIfAAAKTPADAECBCX4AACgwwQ8AAAUm+AEKZPTo0SmVSimVStlnn31y2GGH5eqrr86GDRsqPRoAFbJ3pQcAYNcaMmRIGhsb8/HHH+exxx7LxRdfnA0bNuTWW29tdd7HH3+cffbZp0JTArC7uMMPUDA1NTXp0aNHGhoact5552XUqFGZO3duJk6cmOOOOy533HFHDjvssNTU1KRcLufNN9/M8OHDc8ABB6RTp075+7//+/zv//5vq8+89957079//+y3337p2rVrRo4c2XJs06ZNueaaa/JXf/VX6dixY0488cTMnz+/5fgbb7yRYcOG5aCDDkrHjh3Tr1+/PPDAA0mS999/P6NGjcohhxyS2tra9OnTJ42NjS3vffvtt3P22WfnoIMOysEHH5zhw4fn9ddfbzk+f/78fOMb30jHjh1z4IEH5qSTTsobb7zRNn9YgHbKHX6Agqutrc3HH3+cJFmxYkX+8z//M//1X/+VDh06JElGjBiRjh07ZsGCBdm8eXMuv/zynH322S3Rfv/992fkyJG59tpr8x//8R/ZtGlT7r///pbP/+EPf5jXX389s2bNSn19fe6+++4MGTIkL7zwQvr06ZMxY8Zk06ZNWbhwYTp27JiXXnopBxxwQJLkuuuuy0svvZT//u//TteuXbNixYps3LgxSfLhhx9m0KBB+c53vpOFCxdm7733zo033pghQ4bk+eefz1577ZURI0bkkksuycyZM7Np06Y8/fTTKZVKu/GvC1D9SuVyuVzpIQDYNUaPHp0PPvggc+fOTZI8/fTTOeOMM3LqqafmiCOOyKRJk/L222/nkEMOSZLMmzcvQ4cOTVNTUxoaGpIkL730Uvr165enn346J5xwQgYMGJDDDjssd9111zbf99prr6VPnz556623Ul9f37L/tNNOyze+8Y1MmjQpxxxzTM4666xMmDBhm/d///vfT9euXXPHHXdsc+yOO+7IlClTsmzZspaI37RpUw488MDMnTs3/fv3z8EHH5z58+fnlFNO+cJ/O4CisqQHoGDuu+++HHDAAdlvv/3yrW99KyeffHJuueWWJEmvXr1aYj9Jli1bloaGhpbYT5IjjzwyBx54YJYtW5YkWbp0aU499dRP/a4lS5akXC6nb9++OeCAA1q2BQsW5LXXXkuS/OhHP8qNN96Yk046KRMmTMjzzz/f8v5//Md/zKxZs3LcccflmmuuyRNPPNFybPHixVmxYkXq6upaPrdLly756KOP8tprr6VLly4ZPXp0/vqv/zrDhg3LzTffnHfffXfX/SEBCkLwAxTMoEGDsnTp0rzyyiv56KOPMmfOnHTr1i1J0rFjx1bnlsvlT10C8+f7a2trt/tdW7duTYcOHbJ48eIsXbq0ZVu2bFluvvnmJMnFF1+c3//+9/nBD36QF154If3792/5B8jQoUPzxhtvZOzYsXnnnXdy6qmn5uqrr2757OOPP77V5y5dujSvvvpqzjvvvCRJY2NjnnzyyQwYMCCzZ89O3759s2jRoi/4FwQoFsEPUDAdO3bMV77ylfTq1WuHT+E58sgj8+abb2blypUt+1566aWsWbMmRxxxRJLkmGOOySOPPPKp7//a176WLVu2ZPXq1fnKV77SauvRo0fLeQ0NDbnssssyZ86c/PjHP87tt9/ecuyQQw7J6NGjc9ddd2XatGm57bbbkiRf//rXs3z58nTr1m2bz+7cuXOrGcaPH58nnngiRx11VGbMmLHzfzSAAhP8AHuw0047Lcccc0xGjRqVJUuW5Omnn87555+fU045Jf3790+STJgwITNnzsyECROybNmyvPDCC5kyZUqSpG/fvhk1alTOP//8zJkzJ01NTXnmmWdy0003tTyJZ+zYsXnooYfS1NSUJUuW5NFHH235x8T111+fe+65JytWrMiLL76Y++67r+XYqFGj0rVr1wwfPjyPPfZYmpqasmDBglx11VV566230tTUlPHjx+fJJ5/MG2+8kYcffjivvvpqy/sB+BPBD7AHK5VKmTt3bg466KCcfPLJOe2003LYYYdl9uzZLecMHDgwv/nNb3LvvffmuOOOy3e/+9089dRTLccbGxtz/vnn58c//nEOP/zwfP/7389TTz3V8ruALVu2ZMyYMTniiCMyZMiQHH744fnFL36RJNl3330zfvz4HHPMMTn55JPToUOHzJo1K0my//77Z+HChTn00EMzcuTIHHHEEbnwwguzcePGdOrUKfvvv39efvnlnHXWWenbt2/+4R/+IVdccUUuvfTS3fgXBKh+ntIDAAAF5g4/AAAUmOAHAIACE/wAAFBggh8AAApM8AMAQIEJfgAAKDDBDwAABSb4AQCgwAQ/AAAUmOAHAIACE/wAAFBggh8AAArs/wMdBOcJPh1OsQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 900x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(9,4))\n",
    "plt.bar(range(len(n_processes)), times)\n",
    "plt.xticks(range(len(n_processes)), n_processes)\n",
    "plt.xlabel(\"Processes\")\n",
    "plt.ylabel(\"Time\")\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ce7d0c9f",
   "metadata": {},
   "source": [
    "In this specific case, it seems useful to run our hyper parameter search with a large number of processes\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
