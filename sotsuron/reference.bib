@article{berryLearningTheoryDynamical2023a,
  title = {Learning {{Theory}} for {{Dynamical Systems}}},
  author = {Berry, Tyrus and Das, Suddhasattwa},
  year = {2023},
  month = sep,
  journal = {SIAM J. Appl. Dyn. Syst.},
  volume = {22},
  number = {3},
  pages = {2082--2122},
  publisher = {{Society for Industrial and Applied Mathematics}},
  doi = {10.1137/22M1516865},
  urldate = {2023-12-01},
  abstract = {.In this paper, we consider the density estimation problem associated with the stationary measure of ergodic It{\^o} diffusions from a discrete-time series that approximate the solutions of the stochastic differential equations. To take advantage of the characterization of density function through the stationary solution of a parabolic-type Fokker{\textendash}Planck PDE, we proceed as follows: First, we employ deep neural networks to approximate the drift and diffusion terms of the SDE by solving appropriate supervised learning tasks. Subsequently, we solve a steady-state Fokker{\textendash}Planck equation associated with the estimated drift and diffusion coefficients with a neural-network{\textendash}based least squares method. We establish the convergence of the proposed scheme under appropriate mathematical assumptions, accounting for the generalization errors induced by regressing the drift and diffusion coefficients and the PDE solvers. This theoretical study relies on a recent perturbation theory of Markov chain result that shows a linear dependence of the density estimation to the error in estimating the drift term and generalization error results of nonparametric regression and PDE regression solution obtained with neural-network models. We demonstrate the effectiveness of this method by numerical simulations of a two-dimensional Student t-distribution and a 20-dimensional Langevin dynamics.},
  file = {/Users/manqueenmannequin/Zotero/storage/XQZSHRMZ/Berry and Das - 2023 - Learning Theory for Dynamical Systems.pdf}
}

@article{bolltExplainingSurprisingSuccess2021,
  title = {On Explaining the Surprising Success of Reservoir Computing Forecaster of Chaos? {{The}} Universal Machine Learning Dynamical System with Contrast to {{VAR}} and {{DMD}}},
  shorttitle = {On Explaining the Surprising Success of Reservoir Computing Forecaster of Chaos?},
  author = {Bollt, Erik},
  year = {2021},
  month = jan,
  journal = {Chaos: An Interdisciplinary Journal of Nonlinear Science},
  volume = {31},
  number = {1},
  pages = {013108},
  issn = {1054-1500},
  doi = {10.1063/5.0024890},
  urldate = {2024-01-05},
  abstract = {Machine learning has become a widely popular and successful paradigm, especially in data-driven science and engineering. A major application problem is data-driven forecasting of future states from a complex dynamical system. Artificial neural networks have evolved as a clear leader among many machine learning approaches, and recurrent neural networks are considered to be particularly well suited for forecasting dynamical systems. In this setting, the echo-state networks or reservoir computers (RCs) have emerged for their simplicity and computational complexity advantages. Instead of a fully trained network, an RC trains only readout weights by a simple, efficient least squares method. What is perhaps quite surprising is that nonetheless, an RC succeeds in making high quality forecasts, competitively with more intensively trained methods, even if not the leader. There remains an unanswered question as to why and how an RC works at all despite randomly selected weights. To this end, this work analyzes a further simplified RC, where the internal activation function is an identity function. Our simplification is not presented for the sake of tuning or improving an RC, but rather for the sake of analysis of what we take to be the surprise being not that it does not work better, but that such random methods work at all. We explicitly connect the RC with linear activation and linear readout to well developed time-series literature on vector autoregressive (VAR) averages that includes theorems on representability through the Wold theorem, which already performs reasonably for short-term forecasts. In the case of a linear activation and now popular quadratic readout RC, we explicitly connect to a nonlinear VAR, which performs quite well. Furthermore, we associate this paradigm to the now widely popular dynamic mode decomposition; thus, these three are in a sense different faces of the same thing. We illustrate our observations in terms of popular benchmark examples including Mackey{\textendash}Glass differential delay equations and the Lorenz63 system.},
  file = {/Users/manqueenmannequin/Zotero/storage/CDVQ3ILW/Bollt - 2021 - On explaining the surprising success of reservoir .pdf;/Users/manqueenmannequin/Zotero/storage/3MTKHEVE/On-explaining-the-surprising-success-of-reservoir.html}
}

@article{grigoryevaChaosCompactManifolds2021,
  title = {Chaos on Compact Manifolds: {{Differentiable}} Synchronizations beyond the {{Takens}} Theorem},
  shorttitle = {Chaos on Compact Manifolds},
  author = {Grigoryeva, Lyudmila and Hart, Allen and Ortega, Juan-Pablo},
  year = {2021},
  month = jun,
  journal = {Phys. Rev. E},
  volume = {103},
  number = {6},
  pages = {062204},
  publisher = {{American Physical Society}},
  doi = {10.1103/PhysRevE.103.062204},
  urldate = {2023-12-02},
  abstract = {This paper shows that a large class of fading memory state-space systems driven by discrete-time observations of dynamical systems defined on compact manifolds always yields continuously differentiable synchronizations. This general result provides a powerful tool for the representation, reconstruction, and forecasting of chaotic attractors. It also improves previous statements in the literature for differentiable generalized synchronizations, whose existence was so far guaranteed for a restricted family of systems and was detected using H{\"o}lder exponent-based criteria.},
  file = {/Users/manqueenmannequin/Zotero/storage/VI7LBJWN/Grigoryeva et al. - 2021 - Chaos on compact manifolds Differentiable synchro.pdf;/Users/manqueenmannequin/Zotero/storage/E4UKF6ZR/PhysRevE.103.html}
}

@article{grigoryevaLearningStrangeAttractors2023,
  title = {Learning Strange Attractors with Reservoir Systems},
  author = {Grigoryeva, Lyudmila and Hart, Allen and Ortega, Juan-Pablo},
  year = {2023},
  month = sep,
  journal = {Nonlinearity},
  volume = {36},
  number = {9},
  eprint = {2108.05024},
  primaryclass = {cs, eess, math},
  pages = {4674--4708},
  issn = {0951-7715, 1361-6544},
  doi = {10.1088/1361-6544/ace492},
  urldate = {2023-12-02},
  abstract = {This paper shows that the celebrated Embedding Theorem of Takens is a particular case of a much more general statement according to which, randomly generated linear state-space representations of generic observations of an invertible dynamical system carry in their wake an embedding of the phase space dynamics into the chosen Euclidean state space. This embedding coincides with a natural generalized synchronization that arises in this setup and that yields a topological conjugacy between the state-space dynamics driven by the generic observations of the dynamical system and the dynamical system itself. This result provides additional tools for the representation, learning, and analysis of chaotic attractors and sheds additional light on the reservoir computing phenomenon that appears in the context of recurrent neural networks.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing,Electrical Engineering and Systems Science - Systems and Control,Mathematics - Dynamical Systems},
  file = {/Users/manqueenmannequin/Zotero/storage/WF7YSR3I/Grigoryeva et al. - 2023 - Learning strange attractors with reservoir systems.pdf;/Users/manqueenmannequin/Zotero/storage/94ZJWS64/2108.html}
}

@article{grigoryevaUniversalDiscretetimeReservoir2018,
  title = {Universal Discrete-Time Reservoir Computers with Stochastic Inputs and Linear Readouts Using Non-Homogeneous State-Affine Systems},
  author = {Grigoryeva, Lyudmila and Ortega, Juan-Pablo},
  year = {2018},
  month = sep,
  journal = {Journal of Machine Learning Research},
  volume = {19},
  pages = {1--40},
  abstract = {A new class of non-homogeneous state-affine systems is introduced. Sufficient conditions are identified that guarantee first, that the associated reservoir computers with linear readouts are causal, time-invariant, and satisfy the fading memory property and second, that a subset of this class is universal in the category of fading memory filters with stochastic almost surely bounded inputs. This means that any discrete-time filter that satisfies the fading memory property with random inputs of that type can be uniformly approximated by elements in the non-homogeneous state-affine family.},
  file = {/Users/manqueenmannequin/Zotero/storage/D2CE4G5M/Grigoryeva and Ortega - 2018 - Universal discrete-time reservoir computers with s.pdf}
}

@misc{kongDigitalTwinsNonlinear2022,
  title = {Digital Twins of Nonlinear Dynamical Systems},
  author = {Kong, Ling-Wei and Weng, Yang and Glaz, Bryan and Haile, Mulugeta and Lai, Ying-Cheng},
  year = {2022},
  month = oct,
  number = {arXiv:2210.06144},
  eprint = {2210.06144},
  primaryclass = {nlin},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2210.06144},
  urldate = {2023-11-22},
  abstract = {We articulate the design imperatives for machine-learning based digital twins for nonlinear dynamical systems subject to external driving, which can be used to monitor the ``health'' of the target system and anticipate its future collapse. We demonstrate that, with single or parallel reservoir computing configurations, the digital twins are capable of challenging forecasting and monitoring tasks. Employing prototypical systems from climate, optics and ecology, we show that the digital twins can extrapolate the dynamics of the target system to certain parameter regimes never experienced before, make continual forecasting/monitoring with sparse real-time updates under non-stationary external driving, infer hidden variables and accurately predict their dynamical evolution, adapt to different forms of external driving, and extrapolate the global bifurcation behaviors to systems of some different sizes. These features make our digital twins appealing in significant applications such as monitoring the health of critical systems and forecasting their potential collapse induced by environmental changes.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Nonlinear Sciences - Adaptation and Self-Organizing Systems},
  file = {/Users/manqueenmannequin/Zotero/storage/HNNMKAG4/Kong et al. - 2022 - Digital twins of nonlinear dynamical systems.pdf;/Users/manqueenmannequin/Zotero/storage/QEFYBVYT/2210.html}
}

@article{koriAcceleratingRecoveryJet2017,
  title = {Accelerating Recovery from Jet Lag: Prediction from a Multi-Oscillator Model and Its Experimental Confirmation in Model Animals},
  shorttitle = {Accelerating Recovery from Jet Lag},
  author = {Kori, Hiroshi and Yamaguchi, Yoshiaki and Okamura, Hitoshi},
  year = {2017},
  month = apr,
  journal = {Sci Rep},
  volume = {7},
  number = {1},
  pages = {46702},
  publisher = {{Nature Publishing Group}},
  issn = {2045-2322},
  doi = {10.1038/srep46702},
  urldate = {2024-01-05},
  abstract = {The endogenous circadian clock drives oscillations that are completely synchronized with the environmental day{\textendash}night rhythms with a period of approximately 24\,hours. Temporal misalignment between one's internal circadian clock and the external solar time often occurs in shift workers and long-distance travelers; such misalignments are accompanied by sleep disturbances and gastrointestinal distress. Repeated exposure to jet lag and rotating shift work increases the risk of lifestyle-related diseases, such as cardiovascular complaints and metabolic insufficiencies. However, the mechanism behind the disruption of one's internal clock is not well understood. In this paper, we therefore present a new theoretical concept called ``jet lag separatrix'' to understand circadian clock disruption and slow recovery from jet lag based on the mathematical model describing the hierarchical structure of the circadian clock. To demonstrate the utility of our theoretical study, we applied it to predict that re-entrainment via a two-step jet lag in which a four-hour shift of the light-dark cycle is given in the span of two successive days requires fewer days than when given as a single eight-hour shift. We experimentally verified the feasibility of our theory in C57BL/6 strain mice, with results indicating that this pre-exposure of jet lag is indeed beneficial.},
  copyright = {2017 The Author(s)},
  langid = {english},
  keywords = {Circadian rhythms,Nonlinear dynamics,Nonlinear phenomena},
  file = {/Users/manqueenmannequin/Zotero/storage/L79CKLW8/Kori et al. - 2017 - Accelerating recovery from jet lag prediction fro.pdf}
}

@book{strogatz2018nonlinear,
  title = {Nonlinear Dynamics and Chaos: {{With}} Applications to Physics, Biology, Chemistry, and Engineering},
  author = {Strogatz, S.H.},
  year = {2018},
  publisher = {{CRC Press}},
  isbn = {978-0-429-96111-3}
}

@article{yamaguchiMiceGeneticallyDeficient2013a,
  title = {Mice Genetically Deficient in Vasopressin {{V1a}} and {{V1b}} Receptors Are Resistant to Jet Lag},
  author = {Yamaguchi, Yoshiaki and Suzuki, Toru and Mizoro, Yasutaka and Kori, Hiroshi and Okada, Kazuki and Chen, Yulin and Fustin, Jean-Michel and Yamazaki, Fumiyoshi and Mizuguchi, Naoki and Zhang, Jing and Dong, Xin and Tsujimoto, Gozoh and Okuno, Yasushi and Doi, Masao and Okamura, Hitoshi},
  year = {2013},
  month = oct,
  journal = {Science},
  volume = {342},
  number = {6154},
  pages = {85--90},
  issn = {1095-9203},
  doi = {10.1126/science.1238599},
  abstract = {Jet-lag symptoms arise from temporal misalignment between the internal circadian clock and external solar time. We found that circadian rhythms of behavior (locomotor activity), clock gene expression, and body temperature immediately reentrained to phase-shifted light-dark cycles in mice lacking vasopressin receptors V1a and V1b (V1a(-/-)V1b(-/-)). Nevertheless, the behavior of V1a(-/-)V1b(-/-) mice was still coupled to the internal clock, which oscillated normally under standard conditions. Experiments with suprachiasmatic nucleus (SCN) slices in culture suggested that interneuronal communication mediated by V1a and V1b confers on the SCN an intrinsic resistance to external perturbation. Pharmacological blockade of V1a and V1b in the SCN of wild-type mice resulted in accelerated recovery from jet lag, which highlights the potential of vasopressin signaling as a therapeutic target for management of circadian rhythm misalignment, such as jet lag and shift work.},
  langid = {english},
  pmid = {24092737},
  keywords = {Animals,Antidiuretic Hormone Receptor Antagonists,Body Temperature,Cell Communication,{Cells, Cultured},Circadian Rhythm,CLOCK Proteins,Gene Expression Regulation,Jet Lag Syndrome,Mice,{Mice, Knockout},Motor Activity,{Receptors, Vasopressin},Suprachiasmatic Nucleus}
}

@article{zhangSurveyReservoirComputing2023,
  title = {A {{Survey}} on {{Reservoir Computing}} and Its {{Interdisciplinary Applications Beyond Traditional Machine Learning}}},
  author = {Zhang, Heng and Vargas, Danilo Vasconcellos},
  year = {2023},
  journal = {IEEE Access},
  volume = {11},
  pages = {81033--81070},
  issn = {2169-3536},
  doi = {10.1109/ACCESS.2023.3299296},
  urldate = {2023-12-01},
  abstract = {Reservoir computing (RC), first applied to temporal signal processing, is a recurrent neural network in which neurons are randomly connected. Once initialized, the connection strengths remain unchanged. Such a simple structure turns RC into a non-linear dynamical system that maps low-dimensional inputs into a high-dimensional space. The model's rich dynamics, linear separability, and memory capacity then enable a simple linear readout to generate adequate responses for various applications. RC spans areas far beyond machine learning, since it has been shown that the complex dynamics can be realized in various physical hardware implementations and biological devices. This yields greater flexibility and shorter computation time. Moreover, the neuronal responses triggered by the model's dynamics shed light on understanding brain mechanisms that also exploit similar dynamical processes. While the literature on RC is vast and fragmented, here we conduct a unified review of RC's recent developments from machine learning to physics, biology, and neuroscience. We first review the early RC models, and then survey the state-of-the-art models and their applications. We further introduce studies on modeling the brain's mechanisms by RC. Finally, we offer new perspectives on RC development, including reservoir design, coding frameworks unification, physical RC implementations, and interaction between RC, cognitive neuroscience and evolution.},
  keywords = {Theory},
  file = {/Users/manqueenmannequin/Zotero/storage/9RAQUF9J/Zhang and Vargas - 2023 - A Survey on Reservoir Computing and its Interdisci.pdf;/Users/manqueenmannequin/Zotero/storage/9YBGCQW9/10196105.html}
}
